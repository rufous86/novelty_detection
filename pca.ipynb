{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dfeaab1-df87-4d78-b07b-67a654ebc657",
   "metadata": {},
   "source": [
    "# PCA\n",
    "Метод главных компонент (PCA) - это статистический метод уменьшения размерности данных, который позволяет сократить количество переменных, т.е. признаков, в данных. Он основан на нахождении линейно некоррелированных переменных, называемых главными компонентами. PCA очень часто используется в статистике и машинном обучении, поскольку помогает выделить наиболее значимую информацию из всего датасета, который может состоять из сотни признаков [[1](https://spark-school.ru/blogs/pca-spark/)].\n",
    "\n",
    "Принцип метода поиска аномалий PCA можно описать следующим образом:\n",
    "\n",
    "1. Данные выражаются в виде ортонормированных векторов, т.е. угол между ними равен 90°. Это реализуется за счет вычисления собственных векторов (eigenvectors).\n",
    "2. Собственные векторы сортируются в порядке важности, путем рассмотрения вклада каждого в разброс данных в целом.\n",
    "3. Выбираются только самые важные компоненты, т.е. те, которые объясняют данные более полно, чем остальные. А поскольку они уже сортированы, то выбираются первые.\n",
    "4. На основе выбранных главных компонент строится новое пространство признаков, в котором каждый объект представлен более компактно, чем в исходном пространстве признаков. Объекты, которые находятся далеко от центра облака точек в новом пространстве, могут быть считаться аномальными.\n",
    "\n",
    "Таким образом, PCA может использоваться для поиска аномалий в данных. Однако, важно помнить, что PCA является методом уменьшения размерности, и при его использовании может происходить потеря информации. Поэтому, перед применением PCA для поиска аномалий, необходимо тщательно оценить, насколько важна каждая переменная в данных и какие признаки могут быть исключены без потери важной информации.\n",
    "\n",
    "Работа алгоритма:\n",
    "\n",
    "1. Мы загружаем набор данных и применяем PCA для уменьшения размерности данных до n измерений.\n",
    "2. Затем мы реконструируем данные, используя уменьшенную размерность, и вычисляем остатки.\n",
    "3. Мы задаем пороговое значение для остатков, чтобы отличить нормальные и аномальные точки данных.\n",
    "4. Определяем аномальные точки данных, у которых остатки превышают пороговое значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hMh8F-qOummG",
   "metadata": {
    "id": "hMh8F-qOummG"
   },
   "outputs": [],
   "source": [
    "# ! git clone -b ml_and_stat_methods https://github.com/mipt-nd/novelty-detection.git\n",
    "# %cd novelty-detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "CoB8xYIUmKDd",
   "metadata": {
    "id": "CoB8xYIUmKDd"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# ! cp -r /content/drive/MyDrive/Study/MIPT_magistery/qualification_work/data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oG6zyNZfv2W-",
   "metadata": {
    "id": "oG6zyNZfv2W-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def seed_everything(seed):\n",
    "    # фискирует максимум сидов для корректности сравнения разных экспериментов\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EQNqgtR8vutb",
   "metadata": {
    "id": "EQNqgtR8vutb"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee9e0227-7fd9-4006-a06a-d037ea92b22d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ee9e0227-7fd9-4006-a06a-d037ea92b22d",
    "outputId": "0331d22b-1529-4b1c-d29c-eaca3d6f6c73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>1.523030</td>\n",
       "      <td>-0.234153</td>\n",
       "      <td>-0.234137</td>\n",
       "      <td>1.579213</td>\n",
       "      <td>0.767435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.469474</td>\n",
       "      <td>0.542560</td>\n",
       "      <td>-0.463418</td>\n",
       "      <td>-0.465730</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>-1.913280</td>\n",
       "      <td>-1.724918</td>\n",
       "      <td>-0.562288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.012831</td>\n",
       "      <td>0.314247</td>\n",
       "      <td>-0.908024</td>\n",
       "      <td>-1.412304</td>\n",
       "      <td>1.465649</td>\n",
       "      <td>-0.225776</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>-1.424748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.544383</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>-1.150994</td>\n",
       "      <td>0.375698</td>\n",
       "      <td>-0.600639</td>\n",
       "      <td>-0.291694</td>\n",
       "      <td>-0.601707</td>\n",
       "      <td>1.852278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.013497</td>\n",
       "      <td>-1.057711</td>\n",
       "      <td>0.822545</td>\n",
       "      <td>-1.220844</td>\n",
       "      <td>0.208864</td>\n",
       "      <td>-1.959670</td>\n",
       "      <td>-1.328186</td>\n",
       "      <td>0.196861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.063984</td>\n",
       "      <td>1.772509</td>\n",
       "      <td>0.031678</td>\n",
       "      <td>-0.098264</td>\n",
       "      <td>-3.938531</td>\n",
       "      <td>-2.655435</td>\n",
       "      <td>-4.093768</td>\n",
       "      <td>-3.652004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-2.800126</td>\n",
       "      <td>2.593122</td>\n",
       "      <td>-1.268901</td>\n",
       "      <td>2.124984</td>\n",
       "      <td>-0.288220</td>\n",
       "      <td>5.925277</td>\n",
       "      <td>2.746826</td>\n",
       "      <td>5.429896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.151800</td>\n",
       "      <td>-0.353991</td>\n",
       "      <td>-1.345218</td>\n",
       "      <td>-1.488481</td>\n",
       "      <td>1.680586</td>\n",
       "      <td>-0.062468</td>\n",
       "      <td>4.189587</td>\n",
       "      <td>4.496424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-2.554173</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>-0.528646</td>\n",
       "      <td>-1.866863</td>\n",
       "      <td>2.324896</td>\n",
       "      <td>3.114742</td>\n",
       "      <td>4.235808</td>\n",
       "      <td>5.674279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.443346</td>\n",
       "      <td>0.530400</td>\n",
       "      <td>2.877556</td>\n",
       "      <td>2.471239</td>\n",
       "      <td>0.410279</td>\n",
       "      <td>2.146836</td>\n",
       "      <td>4.482715</td>\n",
       "      <td>-0.812745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.496714 -0.138264  0.647689  1.523030 -0.234153 -0.234137  1.579213   \n",
       "1  -0.469474  0.542560 -0.463418 -0.465730  0.241962 -1.913280 -1.724918   \n",
       "2  -1.012831  0.314247 -0.908024 -1.412304  1.465649 -0.225776  0.067528   \n",
       "3  -0.544383  0.110923 -1.150994  0.375698 -0.600639 -0.291694 -0.601707   \n",
       "4  -0.013497 -1.057711  0.822545 -1.220844  0.208864 -1.959670 -1.328186   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "32  0.063984  1.772509  0.031678 -0.098264 -3.938531 -2.655435 -4.093768   \n",
       "38 -2.800126  2.593122 -1.268901  2.124984 -0.288220  5.925277  2.746826   \n",
       "5   2.151800 -0.353991 -1.345218 -1.488481  1.680586 -0.062468  4.189587   \n",
       "37 -2.554173  0.008819 -0.528646 -1.866863  2.324896  3.114742  4.235808   \n",
       "47  1.443346  0.530400  2.877556  2.471239  0.410279  2.146836  4.482715   \n",
       "\n",
       "           7  anomaly  \n",
       "0   0.767435        0  \n",
       "1  -0.562288        0  \n",
       "2  -1.424748        0  \n",
       "3   1.852278        0  \n",
       "4   0.196861        0  \n",
       "..       ...      ...  \n",
       "32 -3.652004        1  \n",
       "38  5.429896        1  \n",
       "5   4.496424        1  \n",
       "37  5.674279        1  \n",
       "47 -0.812745        1  \n",
       "\n",
       "[1050 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Синтетически сгенерированные нормально распределенные данные\n",
    "def make_norm_data(rows, columns, noise_percent=0.05):\n",
    "    data_norm = pd.DataFrame(data=np.random.normal(\n",
    "                            loc=0, scale=1, size=(rows, columns)))\n",
    "    noise = pd.DataFrame(data=np.random.uniform(\n",
    "                            low=-6, high=6, size=(int(data_norm.shape[0]*noise_percent), data_norm.shape[1])))\n",
    "\n",
    "    data_noise = pd.DataFrame()\n",
    "    for feature in noise.columns:\n",
    "        filter = (\n",
    "            (noise[feature] < data_norm[feature].min())\n",
    "            | (noise[feature] > data_norm[feature].max())\n",
    "            )\n",
    "        data_noise = pd.concat([data_noise, noise[filter]])\n",
    "    data_noise = data_noise.drop_duplicates()\n",
    "    data_norm['anomaly'] = 0\n",
    "    data_noise['anomaly'] = 1\n",
    "\n",
    "    df_norm = pd.concat((data_norm, data_noise))\n",
    "    return df_norm\n",
    "\n",
    "df_norm = make_norm_data(1000, 8)\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dKs4YU3vx_d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "7dKs4YU3vx_d",
    "outputId": "793f82f0-797f-4f58-96e5-4e8e5fb13981"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accelerometer1RMS</th>\n",
       "      <th>Accelerometer2RMS</th>\n",
       "      <th>Current</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Thermocouple</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Volume Flow RateRMS</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-08 16:06:48</th>\n",
       "      <td>0.213628</td>\n",
       "      <td>0.266664</td>\n",
       "      <td>2.588900</td>\n",
       "      <td>-0.273216</td>\n",
       "      <td>89.1732</td>\n",
       "      <td>29.3477</td>\n",
       "      <td>231.257</td>\n",
       "      <td>125.3240</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-08 16:06:49</th>\n",
       "      <td>0.214988</td>\n",
       "      <td>0.267634</td>\n",
       "      <td>2.994500</td>\n",
       "      <td>0.382638</td>\n",
       "      <td>89.3237</td>\n",
       "      <td>29.3409</td>\n",
       "      <td>234.948</td>\n",
       "      <td>125.6780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-08 16:06:50</th>\n",
       "      <td>0.212976</td>\n",
       "      <td>0.268121</td>\n",
       "      <td>2.849810</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>88.9180</td>\n",
       "      <td>29.3450</td>\n",
       "      <td>208.112</td>\n",
       "      <td>125.3240</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-08 16:06:51</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.267545</td>\n",
       "      <td>2.884770</td>\n",
       "      <td>-0.273216</td>\n",
       "      <td>89.0148</td>\n",
       "      <td>29.3459</td>\n",
       "      <td>206.579</td>\n",
       "      <td>125.6780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-08 16:06:52</th>\n",
       "      <td>0.213402</td>\n",
       "      <td>0.266691</td>\n",
       "      <td>2.595010</td>\n",
       "      <td>0.382638</td>\n",
       "      <td>88.9571</td>\n",
       "      <td>29.3462</td>\n",
       "      <td>223.472</td>\n",
       "      <td>125.3240</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 17:14:04</th>\n",
       "      <td>0.026853</td>\n",
       "      <td>0.038926</td>\n",
       "      <td>0.740614</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>69.6371</td>\n",
       "      <td>24.1045</td>\n",
       "      <td>237.276</td>\n",
       "      <td>32.0451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 17:14:05</th>\n",
       "      <td>0.027067</td>\n",
       "      <td>0.038430</td>\n",
       "      <td>0.988875</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>69.6731</td>\n",
       "      <td>24.1046</td>\n",
       "      <td>230.729</td>\n",
       "      <td>32.9562</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 17:14:07</th>\n",
       "      <td>0.027582</td>\n",
       "      <td>0.038836</td>\n",
       "      <td>0.588439</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>69.6959</td>\n",
       "      <td>24.1020</td>\n",
       "      <td>233.443</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 17:14:08</th>\n",
       "      <td>0.027406</td>\n",
       "      <td>0.038133</td>\n",
       "      <td>0.989732</td>\n",
       "      <td>-0.273216</td>\n",
       "      <td>69.6293</td>\n",
       "      <td>24.1020</td>\n",
       "      <td>238.930</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 17:14:09</th>\n",
       "      <td>0.027102</td>\n",
       "      <td>0.039890</td>\n",
       "      <td>0.558126</td>\n",
       "      <td>-0.273216</td>\n",
       "      <td>69.7253</td>\n",
       "      <td>24.0972</td>\n",
       "      <td>219.653</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36920 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accelerometer1RMS  Accelerometer2RMS   Current  Pressure  \\\n",
       "datetime                                                                        \n",
       "2020-02-08 16:06:48           0.213628           0.266664  2.588900 -0.273216   \n",
       "2020-02-08 16:06:49           0.214988           0.267634  2.994500  0.382638   \n",
       "2020-02-08 16:06:50           0.212976           0.268121  2.849810  0.054711   \n",
       "2020-02-08 16:06:51           0.214286           0.267545  2.884770 -0.273216   \n",
       "2020-02-08 16:06:52           0.213402           0.266691  2.595010  0.382638   \n",
       "...                                ...                ...       ...       ...   \n",
       "2020-03-09 17:14:04           0.026853           0.038926  0.740614  0.054711   \n",
       "2020-03-09 17:14:05           0.027067           0.038430  0.988875  0.054711   \n",
       "2020-03-09 17:14:07           0.027582           0.038836  0.588439  0.054711   \n",
       "2020-03-09 17:14:08           0.027406           0.038133  0.989732 -0.273216   \n",
       "2020-03-09 17:14:09           0.027102           0.039890  0.558126 -0.273216   \n",
       "\n",
       "                     Temperature  Thermocouple  Voltage  Volume Flow RateRMS  \\\n",
       "datetime                                                                       \n",
       "2020-02-08 16:06:48      89.1732       29.3477  231.257             125.3240   \n",
       "2020-02-08 16:06:49      89.3237       29.3409  234.948             125.6780   \n",
       "2020-02-08 16:06:50      88.9180       29.3450  208.112             125.3240   \n",
       "2020-02-08 16:06:51      89.0148       29.3459  206.579             125.6780   \n",
       "2020-02-08 16:06:52      88.9571       29.3462  223.472             125.3240   \n",
       "...                          ...           ...      ...                  ...   \n",
       "2020-03-09 17:14:04      69.6371       24.1045  237.276              32.0451   \n",
       "2020-03-09 17:14:05      69.6731       24.1046  230.729              32.9562   \n",
       "2020-03-09 17:14:07      69.6959       24.1020  233.443              32.0000   \n",
       "2020-03-09 17:14:08      69.6293       24.1020  238.930              32.0000   \n",
       "2020-03-09 17:14:09      69.7253       24.0972  219.653              32.0000   \n",
       "\n",
       "                     anomaly  \n",
       "datetime                      \n",
       "2020-02-08 16:06:48      0.0  \n",
       "2020-02-08 16:06:49      0.0  \n",
       "2020-02-08 16:06:50      0.0  \n",
       "2020-02-08 16:06:51      0.0  \n",
       "2020-02-08 16:06:52      0.0  \n",
       "...                      ...  \n",
       "2020-03-09 17:14:04      0.0  \n",
       "2020-03-09 17:14:05      0.0  \n",
       "2020-03-09 17:14:07      0.0  \n",
       "2020-03-09 17:14:08      0.0  \n",
       "2020-03-09 17:14:09      0.0  \n",
       "\n",
       "[36920 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SKAB data\n",
    "\n",
    "all_files=[]\n",
    "for root, dirs, files in os.walk(\"data_labeled/SKAB/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "             all_files.append(os.path.join(root, file))\n",
    "\n",
    "# формируем датафрейм\n",
    "dfs=[]\n",
    "for path in all_files:\n",
    "    df = pd.read_csv(path,index_col='datetime',sep=';',parse_dates=True)\n",
    "    # print(path, df.shape)\n",
    "    dfs.append(df)\n",
    "dfs = [df for df in dfs if df.shape[1] == 10]\n",
    "df_skab = pd.concat(dfs)\n",
    "df_skab = df_skab.drop_duplicates()\n",
    "df_skab = df_skab.drop('changepoint', axis=1).sort_index()\n",
    "display(df_skab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "IVG9gs6YwNQq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "IVG9gs6YwNQq",
    "outputId": "dfb8f505-5ec0-4eae-eea6-abd0774458ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pageblocks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.397679</td>\n",
       "      <td>0.873134</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.030797</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.247890</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.336498</td>\n",
       "      <td>0.726013</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.472574</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       att1      att2      att3      att4      att5      att6      att7  \\\n",
       "0  0.004981  0.010870  0.000194  0.002594  0.367089  0.634328  0.000268   \n",
       "1  0.006227  0.010870  0.000243  0.002160  0.397679  0.873134  0.000525   \n",
       "2  0.006227  0.030797  0.000701  0.005574  0.247890  0.723881  0.000692   \n",
       "3  0.004981  0.010870  0.000194  0.002594  0.336498  0.726013  0.000672   \n",
       "4  0.006227  0.003623  0.000076  0.000918  0.472574  0.940299  0.000252   \n",
       "\n",
       "       att8      att9     att10  anomaly  \n",
       "0  0.000212  0.000347  0.001557        0  \n",
       "1  0.000333  0.000650  0.001246        0  \n",
       "2  0.000727  0.001583  0.001869        0  \n",
       "3  0.000182  0.000412  0.000623        0  \n",
       "4  0.000061  0.000217  0.000934        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_shuttle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.207865</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.746875</td>\n",
       "      <td>0.737113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.207865</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.746875</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.207865</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.746875</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.653409</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       att1      att2     att3      att4      att5      att6      att7  \\\n",
       "0  0.214286  0.607955  0.12766  0.020145  0.207865  0.088428  0.347222   \n",
       "1  0.085714  0.607955  0.12766  0.020145  0.207865  0.088428  0.458333   \n",
       "2  0.200000  0.607955  0.12766  0.020145  0.067416  0.088428  0.361111   \n",
       "3  0.085714  0.602273  0.12766  0.020145  0.207865  0.088428  0.472222   \n",
       "4  0.185714  0.653409  0.12766  0.020145  0.067416  0.088428  0.375000   \n",
       "\n",
       "       att8      att9  anomaly  \n",
       "0  0.746875  0.737113        1  \n",
       "1  0.746875  0.716495        1  \n",
       "2  0.912500  0.871134        1  \n",
       "3  0.746875  0.716495        1  \n",
       "4  0.912500  0.865979        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# labeled data (https://github.com/xuhongzuo/deep-iforest)\n",
    "\n",
    "df_pageblocks = pd.read_csv('data_labeled/pageblocks_16.csv')\n",
    "df_pageblocks = df_pageblocks.rename(columns={'label': 'anomaly'})\n",
    "df_shuttle = pd.read_csv('data_labeled/shuttle_16.csv')\n",
    "df_shuttle = df_shuttle.rename(columns={'label': 'anomaly'})\n",
    "print('df_pageblocks')\n",
    "display(df_pageblocks.head())\n",
    "print('df_shuttle')\n",
    "display(df_shuttle.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ctwHo11HgmyW",
   "metadata": {
    "id": "ctwHo11HgmyW"
   },
   "outputs": [],
   "source": [
    "# для автоматизации формируем словарь из наборов данных \n",
    "\n",
    "datasets = {\n",
    "    'df_norm': df_norm,\n",
    "    'df_skab': df_skab,\n",
    "    'df_pageblocks': df_pageblocks,\n",
    "    'df_shuttle': df_shuttle\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MLsoiQw96Stc",
   "metadata": {
    "id": "MLsoiQw96Stc"
   },
   "source": [
    "# Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Hv1Q_2Wm6NAF",
   "metadata": {
    "id": "Hv1Q_2Wm6NAF"
   },
   "outputs": [],
   "source": [
    "# воспользуемся методом classification_report из sklearn\n",
    "\n",
    "def score_metrics(real_outliers, pred_outliers, output_dict=False):\n",
    "    scores = {}\n",
    "    # scores['f1_score'] = f1_score(real_outliers, pred_outliers)\n",
    "    scores = classification_report(real_outliers, pred_outliers, output_dict=output_dict)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b643a113-ef78-4b52-a33d-63cb0c385b06",
   "metadata": {
    "id": "b643a113-ef78-4b52-a33d-63cb0c385b06"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6ec4a8-615d-4fef-9393-69ce5dceb0c8",
   "metadata": {
    "id": "1e6ec4a8-615d-4fef-9393-69ce5dceb0c8"
   },
   "outputs": [],
   "source": [
    "def preprocessing(df, scaler):\n",
    "    df = df.drop_duplicates()\n",
    "    X = df.copy()\n",
    "    y = X.pop('anomaly')\n",
    "\n",
    "    # preprocessing\n",
    "    columns = list(X.columns)\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(data=X, columns=columns)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de681248-a7c3-4fd2-a799-e129e39e0cf6",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19748641-d12a-46d9-8136-48bb44977534",
   "metadata": {},
   "source": [
    "В этом примере мы загружаем набор данных и применяем PCA для уменьшения размерности данных до n измерений (автоподбор по методу [Minka's MLE](https://vismod.media.mit.edu/tech-reports/TR-514.pdf)). Затем мы реконструируем данные, используя уменьшенную размерность, и вычисляем остатки. Затем задается пороговое значение для остатков, чтобы отличить нормальные и аномальные точки данных. Точки данных, у которых остатки превышают пороговое значение - аномальные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16e31a34-9a20-4879-b880-dca60c870b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std scaler\n",
      "df_norm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       0.94      1.00      0.97        50\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       0.97      1.00      0.98      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "----------\n",
      "df_skab\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.99      0.80     23851\n",
      "         1.0       0.82      0.12      0.20     13067\n",
      "\n",
      "    accuracy                           0.68     36918\n",
      "   macro avg       0.75      0.55      0.50     36918\n",
      "weighted avg       0.72      0.68      0.59     36918\n",
      "\n",
      "----------\n",
      "df_pageblocks\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      4883\n",
      "           1       0.18      0.10      0.13       510\n",
      "\n",
      "    accuracy                           0.87      5393\n",
      "   macro avg       0.55      0.53      0.53      5393\n",
      "weighted avg       0.84      0.87      0.86      5393\n",
      "\n",
      "----------\n",
      "df_shuttle\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1000\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.94      1013\n",
      "   macro avg       0.49      0.47      0.48      1013\n",
      "weighted avg       0.97      0.94      0.95      1013\n",
      "\n",
      "----------\n",
      "MinMax scaler\n",
      "df_norm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1000\n",
      "           1       0.62      0.66      0.64        50\n",
      "\n",
      "    accuracy                           0.96      1050\n",
      "   macro avg       0.80      0.82      0.81      1050\n",
      "weighted avg       0.97      0.96      0.97      1050\n",
      "\n",
      "----------\n",
      "df_skab\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.99      0.80     23851\n",
      "         1.0       0.82      0.12      0.20     13067\n",
      "\n",
      "    accuracy                           0.68     36918\n",
      "   macro avg       0.75      0.55      0.50     36918\n",
      "weighted avg       0.72      0.68      0.59     36918\n",
      "\n",
      "----------\n",
      "df_pageblocks\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      4883\n",
      "           1       0.18      0.09      0.12       510\n",
      "\n",
      "    accuracy                           0.87      5393\n",
      "   macro avg       0.54      0.52      0.53      5393\n",
      "weighted avg       0.84      0.87      0.86      5393\n",
      "\n",
      "----------\n",
      "df_shuttle\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1000\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.94      1013\n",
      "   macro avg       0.49      0.47      0.48      1013\n",
      "weighted avg       0.97      0.94      0.95      1013\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "scalers = {'std scaler': StandardScaler(),\n",
    "          'MinMax scaler': MinMaxScaler()}\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    print(scaler_name)\n",
    "    for df_name, df in datasets.items():\n",
    "        print(df_name)\n",
    "        X, y = preprocessing(df, scaler)\n",
    "\n",
    "        # Применим PCA для снижения размерности данных\n",
    "        pca = PCA(n_components='mle')\n",
    "        '''\n",
    "        If ``n_components == 'mle'`` and ``svd_solver == 'full'``, Minka's\n",
    "        MLE is used to guess the dimension. Use of ``n_components == 'mle'``\n",
    "        will interpret ``svd_solver == 'auto'`` as ``svd_solver == 'full'``\n",
    "        '''\n",
    "        X_pca = pca.fit_transform(X)\n",
    "\n",
    "        # Реконструируем данные, используя уменьшенную размерность\n",
    "        X_reconstructed = pca.inverse_transform(X_pca)\n",
    "\n",
    "        # Вычислим остатки\n",
    "        residuals = np.linalg.norm(X - X_reconstructed, axis=1)\n",
    "\n",
    "        # Укажем пороговое значение для остатков, чтобы различать нормальные и аномальные точки данных\n",
    "        threshold = np.percentile(residuals, 95)\n",
    "\n",
    "        # Определим аномальные точки данных, у которых остатки превышают пороговое значение\n",
    "        anomalies = X[residuals > threshold]\n",
    "        anomalies['anomaly'] = 1\n",
    "        X['anomaly'] = anomalies['anomaly']\n",
    "        X['anomaly'] = X['anomaly'].fillna(0)\n",
    "\n",
    "        print(score_metrics(y, X['anomaly']))\n",
    "\n",
    "        print('-' * 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
